{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pytorch_lightning"
      ],
      "metadata": {
        "id": "zejwdEaqEx91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install imgaug"
      ],
      "metadata": {
        "id": "AijyED7OGYkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/BrainSegmentation/')"
      ],
      "metadata": {
        "id": "l7LWZrSTFgke"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrEr1VmQDLj0"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "import imgaug.augmenters as iaa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset import BrainDataset\n",
        "from model import UNet\n",
        "\n",
        "augment_pipeline = iaa.Sequential([\n",
        "        iaa.Affine(scale=(0.85, 1.15), rotate=(-45, 45)),\n",
        "        iaa.ElasticTransformation()\n",
        "        ])\n",
        "\n",
        "train_path = Path('/content/drive/MyDrive/BrainSegmentation/Preprocessed/train/')\n",
        "val_path = Path('/content/drive/MyDrive/BrainSegmentation/Preprocessed/val/')\n",
        "\n",
        "train_dataset = BrainDataset(train_path, augment_pipeline)\n",
        "val_dataset = BrainDataset(val_path, None)\n",
        "\n",
        "batch_size = 5\n",
        "num_workers = 4\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
        "\n",
        "class DiceLoss(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "    def forward(self, pred_mask, actual_mask):\n",
        "        pred = torch.flatten(pred_mask)\n",
        "        actual = torch.flatten(actual_mask)\n",
        "        \n",
        "        numerator = (pred * actual).sum()\n",
        "        denominator = pred.sum() + actual.sum() + 1e-8\n",
        "        dice_score = (2 * numerator) / denominator\n",
        "        return 1 - dice_score\n",
        "        \n",
        "class BrainSegmentation(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = UNet()\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
        "        self.loss_function = DiceLoss()\n",
        "        \n",
        "    def forward(self, data):\n",
        "        return torch.sigmoid(self.model(data))\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        slice_data, slice_mask = batch\n",
        "        slice_mask = slice_mask.float()\n",
        "        pred_mask = self(slice_data)\n",
        "        loss = self.loss_function(pred_mask, slice_mask)\n",
        "        self.log('Train Loss', loss)\n",
        "        \n",
        "        if batch_idx % 50 == 0:\n",
        "            self.log_images(slice_data.cpu(), pred_mask.cpu(), slice_mask.cpu(), 'Train')\n",
        "            \n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        slice_data, slice_mask = batch\n",
        "        slice_mask = slice_mask.float()\n",
        "        pred_mask = self(slice_data)\n",
        "        loss = self.loss_function(pred_mask, slice_mask)\n",
        "        self.log('Val Loss', loss)\n",
        "        \n",
        "        if batch_idx % 2 == 0:\n",
        "            self.log_images(slice_data.cpu(), pred_mask.cpu(), slice_mask.cpu(), 'Val')\n",
        "            \n",
        "        return loss\n",
        "        \n",
        "    def log_images(self, slice_data, pred_mask, slice_mask, name):\n",
        "        pred_mask = pred_mask > 0.5\n",
        "        fig, axis = plt.subplots(1, 2)\n",
        "        \n",
        "        axis[0].imshow(slice_data[0][0], cmap='bone')\n",
        "        actual_mask_ma = np.ma.masked_where(slice_mask[0][0] == 0, slice_mask[0][0])\n",
        "        axis[0].imshow(actual_mask_ma, alpha=0.6)\n",
        "        \n",
        "        axis[1].imshow(slice_data[0][0], cmap='bone')\n",
        "        pred_mask_ma = np.ma.masked_where(pred_mask[0][0] == 0, pred_mask[0][0])\n",
        "        axis[1].imshow(pred_mask_ma, alpha=0.6)\n",
        "        \n",
        "        self.logger.experiment.add_figure(name, fig, self.global_step)\n",
        "        \n",
        "    def configure_optimizers(self):\n",
        "        return [self.optimizer]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize same random values as weights\n",
        "torch.manual_seed(0)\n",
        "model = BrainSegmentation()\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(monitor='Val Loss', save_top_k=10, mode='min')\n",
        "\n",
        "# Assign 0 for CPU training\n",
        "gpus = 1\n",
        "trainer = pl.Trainer(gpus=gpus, logger=TensorBoardLogger(save_dir='./logs'),\n",
        "                     log_every_n_steps=1, callbacks=checkpoint_callback, max_epochs=50)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    trainer.fit(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "DAdwjVYQDYI6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}